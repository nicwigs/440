{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0.1\n",
    "POS_PATH = './trainData/posTrain/'\n",
    "NEG_PATH = './trainData/negTrain/'\n",
    "POS_TEST_PATH = './TestData/posTest/'\n",
    "NEG_TEST_PATH = './TestData/negTest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'[a-zA-Z]+[\\']*[a-zA-Z]+|[;!?$]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the training files.. this will take a sec\n",
    "posFileList = [POS_PATH+f for f in os.listdir(POS_PATH)]\n",
    "negFileList = [NEG_PATH+f for f in os.listdir(NEG_PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posTestList = [POS_TEST_PATH+f for f in os.listdir(POS_TEST_PATH)]\n",
    "negTestList = [NEG_TEST_PATH+f for f in os.listdir(NEG_TEST_PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "getTokens\n",
    "    Creates list of words from multiple files, removes punctuation, lower cases all\n",
    "Input\n",
    "    fileList = list of files in the directory with all tokens of one class\n",
    "Returns\n",
    "    tokens = list of words in all files of given fileList\n",
    "\"\"\"\n",
    "def getTokens(fileList):\n",
    "    tokens = []\n",
    "    for filename in fileList:\n",
    "        with open(filename, 'r', encoding='ISO-8859-1') as f:\n",
    "            rawText = f.read()\n",
    "            tokens += tokenizer.tokenize(rawText)\n",
    "            \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "getFreq\n",
    "    Counts the number of times a word is in a list\n",
    "Input\n",
    "    tokens = list of words\n",
    "Output\n",
    "    d = dictionary with key=word and value = count of word in given list\n",
    "\"\"\"\n",
    "def getFreq(tokens):\n",
    "    d = {}\n",
    "    for word in tokens:\n",
    "        if word in d:\n",
    "            d[word] += 1\n",
    "        else:\n",
    "            d[word] = 1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calcLaplaseSmooth\n",
    "    Calculates the probability of the word given the class with laplase smoothing\n",
    "    Probability is (xi + a)/(N + a*d)\n",
    "        xi =  The number of appearances on of the word w in positive (or neg) documents\n",
    "        a = the pseudo-count\n",
    "        N = The number of total word appearances in positive (or neg) documents.\n",
    "        d = the number of unique words in both negative and positive documents\n",
    "Inputs\n",
    "    word = word we are looking at\n",
    "    dic = dictionary of word counts for specific class (pos or neg)\n",
    "    a = alpha value\n",
    "    d = number of unique words in both negative and positive (or neg) documents\n",
    "    N = number of total word appearances in positive (or neg) documents\n",
    "Outputs\n",
    "    Probability of word given class, with laplase smoothing. \n",
    "\"\"\"\n",
    "def calcLaplaseSmooth(word,dic,a,d,N):\n",
    "    if word in dic:\n",
    "        x = dic[word]\n",
    "    else:\n",
    "        x = 0     \n",
    "    return (x+a)/(N + a*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "getLaplaseSmooth\n",
    "    Calculates the probability of the word given the class with laplase smoothing\n",
    "        for all words in reviews. \n",
    "Inputs\n",
    "    pfl = positive file list\n",
    "    nfl = negative file list\n",
    "    a = alpha value\n",
    "Outputs\n",
    "    cpp, cpn = dictionarys of all words conditional probability - positive and negative\n",
    "\"\"\"\n",
    "def getLaplaseSmooth(pfl,nfl,a):\n",
    "    ptl = getTokens(pfl)                  # list of words from the files in the list\n",
    "    ntl = getTokens(nfl)\n",
    "    \n",
    "    p = getFreq(ptl)                      # dictionary of word frequency, positive\n",
    "    n = getFreq(ntl)\n",
    "    \n",
    "    allWords = set(p.keys())              # creates set of all words - for unique total words\n",
    "    allWords.update(set(n.keys()))\n",
    "    d = len(allWords)\n",
    "\n",
    "    cpp = {}                              # Conditional probability positve dictionary \n",
    "    cpn = {}\n",
    "    \n",
    "    for word in allWords:\n",
    "        cpp[word] = calcLaplaseSmooth(word,p,a,d,len(ptl))\n",
    "        cpn[word] = calcLaplaseSmooth(word,n,a,d,len(ntl))\n",
    "        \n",
    "    return cpp, cpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test\n",
    "    Predicts if review is positive or negative based off probabilites calulated.\n",
    "        To avoid the risk of the computer approximating our probabilities to zeros, use log space\n",
    "            We add log of probabilities instead of multipling all word probabilities P(c = pos|wi)\n",
    "Inputs\n",
    "    fileList = list of files to test with\n",
    "    actualClass = correct class of the review\n",
    "    cpp = conditional probability positive dictionary\n",
    "    cpn = conditional probability negative dictionary\n",
    "Output\n",
    "    r = dictionary of file names and if classified correctly or not (1 or 0)\n",
    "\"\"\"\n",
    "def test(fileList, actualClass, cpp, cpn):\n",
    "    \n",
    "    r = {}                                     # result dictionary\n",
    "    \n",
    "    for filename in fileList:\n",
    "        \n",
    "        tokens = getTokens([filename])         # use other function to get tokens in this file\n",
    "        pp = 0                                 # probability positive count\n",
    "        pn = 0                                 # probability negative count \n",
    "        \n",
    "        for word in tokens:                    # have to sum log of probabilities\n",
    "            if word in cpp:\n",
    "                pp += math.log(cpp[word])\n",
    "            if word in cpn:\n",
    "                pn += math.log(cpn[word])\n",
    "                \n",
    "        if pp > pn and actualClass == 'p':     # Compare sums to determine predicted class\n",
    "            r[filename] = 1\n",
    "        elif pn > pp and actualClass == 'n':\n",
    "            r[filename] = 1\n",
    "        else:\n",
    "            r[filename] = 0\n",
    "            \n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate smoothing and prior\n",
    "conditionalProbPos, conditionalProbNeg = getLaplaseSmooth(posFileList, negFileList,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "resultsP = test(posTestList, 'p', conditionalProbPos, conditionalProbNeg)\n",
    "resultsN = test(negTestList, 'n', conditionalProbPos, conditionalProbNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred \\ Gold \t P \t N\n",
      "P \t \t 73 \t 21\n",
      "N \t \t 16 \t 69\n"
     ]
    }
   ],
   "source": [
    "TP = sum(resultsP.values())\n",
    "FN = len(resultsP.values()) - TP\n",
    "TN = sum(resultsN.values())\n",
    "FP = len(resultsN.values()) - TN\n",
    "acc = (TP+TN)/(TP+FN+FP+TN)\n",
    "print('Pred \\ Gold \\t P \\t N')\n",
    "print('P \\t \\t '+str(TP)+' \\t '+str(FP))\n",
    "print('N \\t \\t '+str(FN)+' \\t '+str(TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: \n",
      "0.7932960893854749\n"
     ]
    }
   ],
   "source": [
    "acc = (TP+TN)/float(TP+FN+FP+TN)\n",
    "print('accuracy is: ')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
